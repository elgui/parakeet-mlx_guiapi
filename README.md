# Parakeet-MLX GUI and API ğŸ¦œâœ¨

A comprehensive GUI and REST API for [parakeet-mlx](https://github.com/senstella/parakeet-mlx), Nvidia's ASR (Automatic Speech Recognition) models optimized for Apple Silicon using MLX.

## Features ğŸš€

- Web GUI for easy transcription of audio files (Gradio interface) ğŸŒ
- REST API endpoints for seamless integration with other applications ğŸ”Œ
- Support for multiple output formats (TXT, SRT, VTT, JSON, CSV) ğŸ“„
- Word-level timestamp highlighting in subtitle formats âœ¨
- Chunking of long audio files for better memory management ğŸ§ 
- Visualization of transcription results with timeline and heatmap ğŸ“Š
- Audio segment extraction and playback ğŸ§
- **Live microphone recording** with direct transcription ğŸ¤
- **Speaker diarization** - identify who said what in multi-speaker audio ğŸ—£ï¸
- **Clipboard integration** for quick copy of transcription results ğŸ“‹
- **Menu bar app** for one-click voice-to-clipboard with model switching and history (macOS) ğŸ–¥ï¸
- **25 languages supported** including English, French, Spanish, German, and more ğŸŒ
- Comprehensive CLI client with pip-installable commands ğŸ’»

## Prerequisites âœ…

- macOS with Apple Silicon (M1/M2/M3/M4) ğŸ
- Python 3.8 or higher ğŸ
- ffmpeg installed ğŸ› ï¸

**Note:** This project is optimized for Apple Silicon. All ML inference runs locally:
- **Transcription:** Uses MLX (Apple's ML framework) - GPU accelerated
- **Diarization:** Uses PyTorch CPU for stability - no CUDA needed

## Quick Start ğŸš€

### Option A: Menu Bar App (Recommended for Daily Use)

```bash
# 1. Install ffmpeg (if not already installed)
brew install ffmpeg

# 2. Clone and enter the repository
git clone https://github.com/yourusername/parakeet-mlx_guiapi.git
cd parakeet-mlx_guiapi

# 3. Create virtual environment and install
python -m venv .venv
source .venv/bin/activate
pip install -e .

# 4. Install the menu bar app
./install_menubar_app.sh
```

This installs **Parakeet.app** to `/Applications`. Launch it from:
- **Spotlight**: Cmd+Space, type "Parakeet"
- **Menu Bar**: Click the ğŸ¤ icon
- **Terminal**: `open /Applications/Parakeet.app`

### Option B: Web GUI + API Server

```bash
# After steps 1-3 above, start the server:
python run.py
```

- **Web GUI**: http://localhost:8081
- **REST API**: http://localhost:8080/api/

The first run will download the model (~1.2GB).

## Usage â–¶ï¸

### Starting the Server ğŸš€

Run the server with:

```bash
python run.py
```

Or with custom options:

```bash
python run.py --host 127.0.0.1 --port 8000 --debug --model <model_name>
```

Server options:
- `--host`: Host to bind to (default: 0.0.0.0)
- `--port`: Port for the Flask API (default: 8080)
- `--debug`: Enable debug mode
- `--model`: Specify the ASR model to use

The server will start and be accessible at:
- Gradio Web GUI: http://localhost:8081 (port + 1) ğŸŒ
- REST API: http://localhost:8080/api/ ğŸ”Œ

Note: The Gradio UI runs on port+1 from the specified port (default: 8081).

### Web GUI ğŸ–¥ï¸

1. Open your browser and navigate to http://localhost:8081 (Gradio interface)
2. Upload an audio file using the interface â¬†ï¸
3. Configure transcription options:
   - Output Format: json, txt, srt, or vtt ğŸ“„
   - Highlight Words: Enable word-level timestamps in SRT/VTT âœ¨
   - Chunk Duration: Duration in seconds for chunking long audio (0 to disable) â±ï¸
   - Overlap Duration: Overlap duration in seconds when using chunking ğŸ”„
4. Click "Transcribe" and view the results ğŸ‰

### REST API ğŸ¤–

The following API endpoints are available:

#### Transcribe Audio ğŸ¤â¡ï¸ğŸ“„

```
POST /api/transcribe
```

Parameters (multipart/form-data):
- `file`: The audio file to transcribe (required) â¬†ï¸
- `output_format`: Format for output (json, txt, srt, vtt, csv) (optional, default: json) ğŸ“„
- `highlight_words`: Enable word-level timestamps (optional, default: false) âœ¨
- `chunk_duration`: Duration in seconds for chunking long audio (optional, default: 120) â±ï¸
- `overlap_duration`: Overlap duration in seconds when using chunking (optional, default: 15) ğŸ”„

Response:
- For JSON format: JSON object with transcription results and visualizations ğŸ“Š
- For other formats: File download with the appropriate content type â¬‡ï¸

Example cURL request:
```bash
curl -X POST -F "file=@audio.mp3" -F "output_format=json" http://localhost:8080/api/transcribe
```

#### Get Audio Segment âœ‚ï¸ğŸ§

```
POST /api/segment
```

Parameters (multipart/form-data):
- `file`: The audio file to extract segment from (required) â¬†ï¸
- `start_time`: Start time in seconds (required) â±ï¸
- `end_time`: End time in seconds (required) â±ï¸

Response:
- WAV audio file containing the requested segment ğŸ§

Example cURL request:
```bash
curl -X POST -F "file=@audio.mp3" -F "start_time=10" -F "end_time=20" http://localhost:8080/api/segment -o segment.wav
```

#### Get Available Models ğŸ§ 

```
GET /api/models
```

Response:
- JSON array of available model names ğŸ“œ

Example cURL request:
```bash
curl http://localhost:8080/api/models
```

### CLI Client ğŸ’»

After installation, you can use the CLI client for file transcription and microphone recording:

#### File Transcription
```bash
# Basic transcription (outputs JSON)
python client.py audio.mp3

# Specify output format
python client.py audio.mp3 --output-format srt

# With chunking for long audio files
python client.py audio.mp3 --output-format json --chunk-duration 120

# Extract a specific segment
python client.py audio.mp3 --segment 10-20 --output-file segment.wav

# Generate visualization
python client.py audio.mp3 --output-format json --visualize
```

#### Microphone Recording ğŸ¤
```bash
# Record from microphone and transcribe (press Enter to stop)
python client.py --mic

# Record and copy transcription to clipboard
python client.py --mic --clipboard

# Record and save to file
python client.py --mic --output-file transcription.txt
```

#### CLI Options Reference

| Option | Description |
|--------|-------------|
| `--mic` | Record from microphone instead of using a file |
| `--clipboard` | Copy transcription result to clipboard |
| `--api-url` | Base URL for the API (default: http://localhost:8080/api) |
| `--output-format` | Output format: json, txt, srt, vtt, csv (default: json) |
| `--highlight-words` | Enable word-level timestamps in SRT/VTT |
| `--chunk-duration` | Chunking duration in seconds (default: 120, 0 to disable) |
| `--overlap-duration` | Overlap duration in seconds (default: 15) |
| `--output-file` | Output file path |
| `--segment` | Extract segment (format: start_time-end_time) |
| `--visualize` | Generate visualization (JSON output only) |

#### Installable Commands

After installing with pip (`pip install -e .`), these commands are available **when the virtual environment is activated**:

```bash
source .venv/bin/activate  # Activate first!
parakeet-server   # Start the web GUI + API server
parakeet-client   # Run the CLI client
parakeet-menubar  # Launch the menu bar app (dev mode)
```

**Tip:** For daily use without activating venv, install the Parakeet.app instead (see below).

### Menu Bar App (Voice-to-Clipboard) ğŸ“‹

A macOS menu bar app for quick, seamless voice transcription. Click to record, click to stop - transcription is automatically copied to your clipboard.

#### One-Line Install (Recommended) ğŸš€

```bash
./install_menubar_app.sh
```

This script will:
1. Build `Parakeet.app` (alias mode - fast build)
2. Install it to `/Applications`
3. Optionally add it to Login Items (start at boot)
4. Launch the app

**First Launch:**
- If the model isn't cached, Terminal will open showing download progress
- The default model (TDT 0.6B v3 Multilingual, ~1.2GB) downloads automatically
- Status bar shows "Downloading..." until complete

After installation, find **Parakeet** in:
- Your **menu bar** (ğŸ¤ icon in the top-right)
- **Spotlight** (Cmd+Space, type "Parakeet")
- **Applications** folder

#### How It Works
1. A microphone icon (ğŸ¤) appears in your macOS menu bar
2. **Click** the icon to start recording (icon shows ğŸ”´ with timer)
3. **Click again** to stop recording
4. The app transcribes your audio and **automatically copies to clipboard**
5. A notification shows a preview of the transcription

#### Menu Bar Features

| Feature | Description |
|---------|-------------|
| **Model Selection** | Switch between models organized by category (Multilingual, English, Fast, etc.) |
| **Download Progress** | Model downloads show progress in Terminal window |
| **Recording Timer** | See elapsed time while recording (ğŸ”´ 0:15) |
| **Transcription History** | Access last 20 transcriptions, click to copy again |
| **Speaker Diarization** | Identify who said what (requires one-time setup) |
| **Settings** | Configure chunk duration, auto-copy, notifications |
| **Advanced Settings** | View Python/cache paths, pre-download models, open config |
| **Status Display** | See current model and ready/loading state |

#### Available Models

| Model | Languages | WER | Speed | Size | Best For |
|-------|-----------|-----|-------|------|----------|
| â­ **TDT 0.6B v3 Multilingual** | EN, FR, ES, DE + 21 more | 6.34% | Fast | ~1.2GB | **Recommended** - General use |
| TDT 0.6B v2 English | English | 6.5% | Fast | ~1.2GB | English-only, accurate |
| TDT 1.1B English | English | ~5.5% | Slower | ~2.2GB | Meetings, interviews |
| CTC 0.6B English | English | ~7% | Fastest | ~1.2GB | Quick notes, real-time |
| CTC 1.1B English | English | ~6% | Very Fast | ~2.2GB | Long audio, speed priority |
| TDT+CTC 1.1B English | English | ~5.8% | Medium | ~2.2GB | Podcasts, 11hr support |
| TDT+CTC 110M Tiny | English | ~12% | Instant | ~220MB | Ultra-fast loading |

**Supported Languages (v3 Multilingual):**
ğŸ‡¬ğŸ‡§ English, ğŸ‡«ğŸ‡· French, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡©ğŸ‡ª German, ğŸ‡®ğŸ‡¹ Italian, ğŸ‡µğŸ‡¹ Portuguese, ğŸ‡³ğŸ‡± Dutch, ğŸ‡µğŸ‡± Polish, ğŸ‡·ğŸ‡º Russian, ğŸ‡ºğŸ‡¦ Ukrainian, ğŸ‡¨ğŸ‡¿ Czech, ğŸ‡¸ğŸ‡° Slovak, ğŸ‡§ğŸ‡¬ Bulgarian, ğŸ‡­ğŸ‡· Croatian, ğŸ‡©ğŸ‡° Danish, ğŸ‡ªğŸ‡ª Estonian, ğŸ‡«ğŸ‡® Finnish, ğŸ‡¬ğŸ‡· Greek, ğŸ‡­ğŸ‡º Hungarian, ğŸ‡±ğŸ‡» Latvian, ğŸ‡±ğŸ‡¹ Lithuanian, ğŸ‡²ğŸ‡¹ Maltese, ğŸ‡·ğŸ‡´ Romanian, ğŸ‡¸ğŸ‡® Slovenian, ğŸ‡¸ğŸ‡ª Swedish

To change models: Click menu bar icon â†’ **Model** â†’ Select category â†’ Select model

#### Speaker Diarization (Who Said What) ğŸ—£ï¸

The app supports **speaker diarization** - identifying WHO is speaking in multi-speaker recordings. Works with any transcription model.

**Example output with diarization enabled:**
```
SPEAKER_00: Hello, how are you today?

SPEAKER_01: I'm doing great, thanks for asking! How about you?

SPEAKER_00: Pretty good. Let me tell you about our project...
```

**In-App Setup (Recommended):**

The app includes a guided setup wizard:

1. Go to **Settings â†’ Speaker Diarization â†’ Quick Setup**
2. The wizard will:
   - Install pyannote.audio if needed (progress shown in Terminal)
   - Open HuggingFace to accept model license and create token
   - Let you paste the token directly in the app (saved to config)
3. Enable diarization when setup completes

**What you need:**
- A free [HuggingFace account](https://huggingface.co)
- Accept the [pyannote model license](https://huggingface.co/pyannote/speaker-diarization-3.1)
- A **Read** access token (not Write) - the wizard guides you through this

**Apple Silicon Compatibility:**
- Uses PyTorch CPU for maximum stability (no CUDA needed)
- Diarization runs entirely locally after setup
- First use downloads ~1GB model (progress shown)
- Adds ~10-30s processing time depending on audio length

**Manual Setup (Alternative):**

If you prefer command-line setup:
```bash
# Install pyannote
pip install pyannote.audio>=3.1.0

# Save token to config file
echo '{"huggingface_token": "hf_your_token_here"}' > ~/.parakeet_mlx_guiapi.json
```

#### Manual Installation

If you prefer to install manually:

```bash
# 1. Install dependencies
pip install py2app rumps pyobjc-framework-Cocoa parakeet-mlx

# 2. Build the app (alias mode for faster build)
python setup_app.py py2app --alias

# 3. Copy to Applications
cp -R dist/Parakeet.app /Applications/

# 4. Launch
open /Applications/Parakeet.app
```

Note: The app requires Python and dependencies to remain installed (alias mode).

#### Start at Login

To have Parakeet start automatically when you log in:

1. Open **System Settings** (or System Preferences on older macOS)
2. Go to **General â†’ Login Items** (or Users & Groups â†’ Login Items)
3. Click **+** and select `/Applications/Parakeet.app`

Or via Terminal:
```bash
osascript -e 'tell application "System Events" to make login item at end with properties {path:"/Applications/Parakeet.app", hidden:false}'
```

#### Running from Terminal (Development)

For development or testing without building the app:

```bash
# Activate the virtual environment first
source .venv/bin/activate

# Option 1: Run directly
python menubar_app.py

# Option 2: Use the installed command (requires pip install -e .)
parakeet-menubar
```

**Note:** These commands require the virtual environment to be activated. For daily use, install the Parakeet.app which works without activation.

#### Troubleshooting

**"Parakeet" can't be opened because Apple cannot check it for malicious software:**
1. Open **System Settings â†’ Privacy & Security**
2. Scroll down to find the message about Parakeet
3. Click **Open Anyway**

**Microphone permission:**
- The first time you record, macOS will ask for microphone permission
- If denied, go to **System Settings â†’ Privacy & Security â†’ Microphone** and enable Parakeet

## License ğŸ“œ

This project is licensed under the Apache 2.0 License - see the LICENSE file for details.

## Contributing ğŸ‘‹

Pull requests are welcome! Feel free to contribute bug fixes or new features. We appreciate your contributions! ğŸ™

## Acknowledgments ğŸ™Œ

- This project uses [parakeet-mlx](https://github.com/senstella/parakeet-mlx) as its core library
- Thanks to [Nvidia](https://www.nvidia.com/) for training these powerful models
- Thanks to [MLX](https://github.com/ml-explore/mlx) for providing the incredible framework
- Special thanks to [Sam Witteveen](https://github.com/samwit) for his inspirational code and his insightful [YouTube channel](https://www.youtube.com/@samwitteveenai)
